"""
RepurposeAgent - –ê–≥–µ–Ω—Ç –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ–¥ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ–¥–∏–Ω –º–∞—Ç–µ—Ä–∏–∞–ª –≤ 8+ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º
"""

import asyncio
import logging
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum

from app.orchestrator.agent_manager import BaseAgent, AgentCapability, AgentStatus
from app.orchestrator.workflow_engine import TaskType, Task

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)


class ContentFormat(Enum):
    """–§–æ—Ä–º–∞—Ç—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    TELEGRAM_POST = "telegram_post"
    TWITTER_THREAD = "twitter_thread"
    INSTAGRAM_CAROUSEL = "instagram_carousel"
    INSTAGRAM_STORY = "instagram_story"
    LINKEDIN_ARTICLE = "linkedin_article"
    YOUTUBE_SHORTS = "youtube_shorts"
    TIKTOK_VIDEO = "tiktok_video"
    PODCAST_SCRIPT = "podcast_script"
    BLOG_POST = "blog_post"
    NEWSLETTER = "newsletter"
    PRESENTATION = "presentation"
    INFOGRAPHIC = "infographic"


class ContentType(Enum):
    """–¢–∏–ø—ã –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    LONG_ARTICLE = "long_article"
    VIDEO_SCRIPT = "video_script"
    PODCAST_EPISODE = "podcast_episode"
    PRESENTATION_SLIDES = "presentation_slides"
    SOCIAL_MEDIA_POST = "social_media_post"
    NEWSLETTER_CONTENT = "newsletter_content"
    BLOG_POST = "blog_post"
    INTERVIEW_TRANSCRIPT = "interview_transcript"


class AdaptationStrategy(Enum):
    """–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏"""
    EXTRACT_KEY_POINTS = "extract_key_points"
    SUMMARIZE = "summarize"
    EXPAND = "expand"
    RESTRUCTURE = "restructure"
    VISUALIZE = "visualize"
    CONVERSATIONAL = "conversational"


@dataclass
class ContentPiece:
    """–§—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    content_id: str
    format: ContentFormat
    title: str
    content: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    word_count: int = 0
    character_count: int = 0
    hashtags: List[str] = field(default_factory=list)
    mentions: List[str] = field(default_factory=list)
    call_to_action: Optional[str] = None


@dataclass
class RepurposeResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
    source_content_id: str
    source_format: ContentFormat
    adapted_pieces: List[ContentPiece]
    adaptation_strategy: AdaptationStrategy
    success_rate: float
    total_pieces: int
    processing_time: float
    generated_at: datetime = field(default_factory=datetime.now)


@dataclass
class PlatformGuidelines:
    """–†—É–∫–æ–≤–æ–¥—è—â–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã"""
    max_length: int
    min_length: int
    preferred_tone: str
    hashtag_limit: int
    mention_style: str
    call_to_action_required: bool
    visual_elements: List[str] = field(default_factory=list)
    formatting_rules: List[str] = field(default_factory=list)


class RepurposeAgent(BaseAgent):
    """–ê–≥–µ–Ω—Ç –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ–¥ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã"""
    
    def __init__(self, agent_id: str = "repurpose_agent"):
        capability = AgentCapability(
            task_types=[TaskType.PLANNED],  # –¢—Ä–µ–±—É–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            max_concurrent_tasks=3,         # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            specializations=["content_repurposing", "format_adaptation", "cross_platform", "content_optimization"],
            performance_score=1.1          # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        )
        super().__init__(agent_id, "Repurpose Agent", capability)
        
        # –®–∞–±–ª–æ–Ω—ã –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
        self.adaptation_templates = self._load_adaptation_templates()
        self.platform_guidelines = self._load_platform_guidelines()
        self.content_analyzers = self._load_content_analyzers()
        
        # –ö—ç—à –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        self.repurpose_cache = {}
        self.cache_ttl = timedelta(hours=12)  # –ö—ç—à –Ω–∞ 12 —á–∞—Å–æ–≤
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
        self.adaptation_stats = {
            'total_adaptations': 0,
            'successful_adaptations': 0,
            'failed_adaptations': 0,
            'formats_created': {},
            'average_processing_time': 0.0
        }
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        self.quality_thresholds = {
            'min_word_count': 50,
            'max_word_count': 2000,
            'readability_score': 0.7,
            'engagement_potential': 0.6
        }
        
        logger.info(f"RepurposeAgent {agent_id} –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def can_handle_task(self, task: Task) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–µ—Ç –ª–∏ RepurposeAgent –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞—á—É
        –ù–ï –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–¥–∞—á–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (—Å 'Publish' –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏) –∏ –∑–∞–¥–∞—á–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        """
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–µ —É—Å–ª–æ–≤–∏—è
        if not super().can_handle_task(task):
            return False
        
        # RepurposeAgent –ù–ï –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–¥–∞—á–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        if "Publish" in task.name or "publish" in task.name.lower():
            return False
        
        # RepurposeAgent –ù–ï –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–¥–∞—á–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏/–ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        # –≠—Ç–æ –¥–æ–ª–∂–Ω—ã –¥–µ–ª–∞—Ç—å MultimediaProducerAgent
        image_related_keywords = ["Image", "image", "stock", "Stock", "Generate", "generate", "multimedia"]
        if any(keyword in task.name for keyword in image_related_keywords):
            return False  # MultimediaProducerAgent –¥–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
        
        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏
        if task.context.get("content_type") in ["post_image", "image"] or task.context.get("image_source"):
            return False  # MultimediaProducerAgent –¥–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
        
        return True
    
    def _load_adaptation_templates(self) -> Dict[ContentFormat, Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —à–∞–±–ª–æ–Ω—ã –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
        return {
            ContentFormat.TELEGRAM_POST: {
                "max_length": 4096,
                "structure": "hook + main_content + cta",
                "tone": "conversational",
                "hashtags": 3,
                "formatting": ["bold", "italic", "links"]
            },
            ContentFormat.TWITTER_THREAD: {
                "max_length": 280,
                "structure": "thread_intro + points + conclusion",
                "tone": "engaging",
                "hashtags": 2,
                "formatting": ["thread_numbering", "mentions"]
            },
            ContentFormat.INSTAGRAM_CAROUSEL: {
                "max_length": 2200,
                "structure": "hook + slides + cta",
                "tone": "visual_storytelling",
                "hashtags": 30,
                "formatting": ["line_breaks", "emojis"]
            },
            ContentFormat.INSTAGRAM_STORY: {
                "max_length": 100,
                "structure": "quick_hook + value + swipe_up",
                "tone": "casual",
                "hashtags": 5,
                "formatting": ["stories_text", "polls", "questions"]
            },
            ContentFormat.LINKEDIN_ARTICLE: {
                "max_length": 3000,
                "structure": "headline + intro + body + conclusion",
                "tone": "professional",
                "hashtags": 5,
                "formatting": ["headings", "bullet_points", "calls_to_action"]
            },
            ContentFormat.YOUTUBE_SHORTS: {
                "max_length": 500,
                "structure": "hook + value + subscribe",
                "tone": "energetic",
                "hashtags": 3,
                "formatting": ["timestamps", "subscribe_reminder"]
            },
            ContentFormat.TIKTOK_VIDEO: {
                "max_length": 300,
                "structure": "trending_hook + content + follow",
                "tone": "trendy",
                "hashtags": 5,
                "formatting": ["trending_sounds", "effects"]
            },
            ContentFormat.PODCAST_SCRIPT: {
                "max_length": 2000,
                "structure": "intro + segments + outro",
                "tone": "conversational",
                "hashtags": 0,
                "formatting": ["speaker_notes", "timing"]
            },
            ContentFormat.BLOG_POST: {
                "max_length": 2500,
                "structure": "title + intro + sections + conclusion",
                "tone": "informative",
                "hashtags": 10,
                "formatting": ["headings", "subheadings", "links"]
            },
            ContentFormat.NEWSLETTER: {
                "max_length": 1500,
                "structure": "subject + preview + content + footer",
                "tone": "personal",
                "hashtags": 0,
                "formatting": ["personal_greeting", "unsubscribe"]
            },
            ContentFormat.PRESENTATION: {
                "max_length": 1000,
                "structure": "title + agenda + slides + conclusion",
                "tone": "presentation",
                "hashtags": 0,
                "formatting": ["slide_titles", "bullet_points"]
            },
            ContentFormat.INFOGRAPHIC: {
                "max_length": 200,
                "structure": "title + key_points + visual_elements",
                "tone": "visual",
                "hashtags": 5,
                "formatting": ["statistics", "icons", "charts"]
            }
        }
    
    def _load_platform_guidelines(self) -> Dict[ContentFormat, PlatformGuidelines]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä—É–∫–æ–≤–æ–¥—è—â–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –¥–ª—è –ø–ª–∞—Ç—Ñ–æ—Ä–º"""
        return {
            ContentFormat.TELEGRAM_POST: PlatformGuidelines(
                max_length=4096,
                min_length=100,
                preferred_tone="conversational",
                hashtag_limit=5,
                mention_style="@username",
                call_to_action_required=True,
                visual_elements=["images", "videos", "polls"],
                formatting_rules=["Use markdown", "Bold for emphasis", "Links for references"]
            ),
            ContentFormat.TWITTER_THREAD: PlatformGuidelines(
                max_length=280,
                min_length=50,
                preferred_tone="engaging",
                hashtag_limit=3,
                mention_style="@username",
                call_to_action_required=True,
                visual_elements=["images", "videos", "polls"],
                formatting_rules=["Number threads", "Use line breaks", "Engage with questions"]
            ),
            ContentFormat.INSTAGRAM_CAROUSEL: PlatformGuidelines(
                max_length=2200,
                min_length=200,
                preferred_tone="visual_storytelling",
                hashtag_limit=30,
                mention_style="@username",
                call_to_action_required=True,
                visual_elements=["carousel_images", "stories", "reels"],
                formatting_rules=["Use emojis", "Line breaks for readability", "Hashtags at end"]
            ),
            ContentFormat.INSTAGRAM_STORY: PlatformGuidelines(
                max_length=100,
                min_length=20,
                preferred_tone="casual",
                hashtag_limit=5,
                mention_style="@username",
                call_to_action_required=True,
                visual_elements=["stories", "polls", "questions", "swipe_up"],
                formatting_rules=["Short and punchy", "Use story features", "Engage with stickers"]
            ),
            ContentFormat.LINKEDIN_ARTICLE: PlatformGuidelines(
                max_length=3000,
                min_length=500,
                preferred_tone="professional",
                hashtag_limit=5,
                mention_style="@username",
                call_to_action_required=True,
                visual_elements=["images", "videos", "documents"],
                formatting_rules=["Professional tone", "Use headings", "Include insights"]
            ),
            ContentFormat.YOUTUBE_SHORTS: PlatformGuidelines(
                max_length=500,
                min_length=100,
                preferred_tone="energetic",
                hashtag_limit=3,
                mention_style="@channel",
                call_to_action_required=True,
                visual_elements=["shorts_video", "thumbnails", "end_screens"],
                formatting_rules=["Hook in first 3 seconds", "Subscribe reminder", "Trending topics"]
            ),
            ContentFormat.TIKTOK_VIDEO: PlatformGuidelines(
                max_length=300,
                min_length=50,
                preferred_tone="trendy",
                hashtag_limit=5,
                mention_style="@username",
                call_to_action_required=True,
                visual_elements=["trending_sounds", "effects", "filters"],
                formatting_rules=["Follow trends", "Use trending sounds", "Engage with comments"]
            ),
            ContentFormat.PODCAST_SCRIPT: PlatformGuidelines(
                max_length=2000,
                min_length=500,
                preferred_tone="conversational",
                hashtag_limit=0,
                mention_style="natural",
                call_to_action_required=True,
                visual_elements=["intro_music", "outro_music", "ad_breaks"],
                formatting_rules=["Natural speech", "Include timing", "Speaker notes"]
            ),
            ContentFormat.BLOG_POST: PlatformGuidelines(
                max_length=2500,
                min_length=800,
                preferred_tone="informative",
                hashtag_limit=10,
                mention_style="natural",
                call_to_action_required=True,
                visual_elements=["featured_images", "infographics", "videos"],
                formatting_rules=["SEO optimized", "Use headings", "Include links"]
            ),
            ContentFormat.NEWSLETTER: PlatformGuidelines(
                max_length=1500,
                min_length=300,
                preferred_tone="personal",
                hashtag_limit=0,
                mention_style="natural",
                call_to_action_required=True,
                visual_elements=["images", "gifs", "buttons"],
                formatting_rules=["Personal greeting", "Unsubscribe link", "Mobile friendly"]
            ),
            ContentFormat.PRESENTATION: PlatformGuidelines(
                max_length=1000,
                min_length=200,
                preferred_tone="presentation",
                hashtag_limit=0,
                mention_style="natural",
                call_to_action_required=True,
                visual_elements=["slides", "charts", "diagrams"],
                formatting_rules=["Clear structure", "Visual elements", "Speaker notes"]
            ),
            ContentFormat.INFOGRAPHIC: PlatformGuidelines(
                max_length=200,
                min_length=50,
                preferred_tone="visual",
                hashtag_limit=5,
                mention_style="@username",
                call_to_action_required=True,
                visual_elements=["charts", "icons", "statistics"],
                formatting_rules=["Visual focus", "Key statistics", "Clear data"]
            )
        }
    
    def _load_content_analyzers(self) -> Dict[ContentType, Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        return {
            ContentType.LONG_ARTICLE: {
                "extract_method": "key_points_extraction",
                "structure_analysis": True,
                "summary_generation": True,
                "quote_extraction": True
            },
            ContentType.VIDEO_SCRIPT: {
                "extract_method": "scene_analysis",
                "structure_analysis": True,
                "summary_generation": True,
                "quote_extraction": True
            },
            ContentType.PODCAST_EPISODE: {
                "extract_method": "transcript_analysis",
                "structure_analysis": True,
                "summary_generation": True,
                "quote_extraction": True
            },
            ContentType.PRESENTATION_SLIDES: {
                "extract_method": "slide_analysis",
                "structure_analysis": True,
                "summary_generation": True,
                "quote_extraction": False
            },
            ContentType.SOCIAL_MEDIA_POST: {
                "extract_method": "post_analysis",
                "structure_analysis": False,
                "summary_generation": False,
                "quote_extraction": True
            },
            ContentType.NEWSLETTER_CONTENT: {
                "extract_method": "section_analysis",
                "structure_analysis": True,
                "summary_generation": True,
                "quote_extraction": True
            },
            ContentType.BLOG_POST: {
                "extract_method": "paragraph_analysis",
                "structure_analysis": True,
                "summary_generation": True,
                "quote_extraction": True
            },
            ContentType.INTERVIEW_TRANSCRIPT: {
                "extract_method": "qa_analysis",
                "structure_analysis": True,
                "summary_generation": True,
                "quote_extraction": True
            }
        }
    
    async def execute_task(self, task: Task) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–¥–∞—á—É –ø–æ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        try:
            self.status = AgentStatus.BUSY
            self.last_activity = datetime.now()
            
            task_data = task.context
            source_content = task_data.get("content", "")
            source_format = task_data.get("source_format", "long_article")
            target_formats = task_data.get("target_formats", [])
            content_id = task_data.get("content_id", task.id)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cache_key = f"{content_id}_{hash(source_content)}_{'-'.join(target_formats)}"
            if cache_key in self.repurpose_cache:
                cached_result = self.repurpose_cache[cache_key]
                if datetime.now() - cached_result['timestamp'] < self.cache_ttl:
                    logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è {content_id}")
                    return cached_result['result']
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–¥–∞–ø—Ç–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            result = await self._repurpose_content(
                source_content, source_format, target_formats, content_id
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            self.repurpose_cache[cache_key] = {
                'result': result,
                'timestamp': datetime.now()
            }
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self._update_adaptation_stats(result)
            
            self.status = AgentStatus.IDLE
            self.completed_tasks.append(task.id)
            
            logger.info(f"–ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è {content_id}. –°–æ–∑–¥–∞–Ω–æ {result['total_pieces']} —Ñ–æ—Ä–º–∞—Ç–æ–≤")
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}")
            self.status = AgentStatus.ERROR
            self.error_count += 1
            raise
    
    async def _repurpose_content(self, source_content: str, source_format: str, target_formats: List[str], content_id: str) -> Dict[str, Any]:
        """–ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ–¥ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã"""
        start_time = datetime.now()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        content_analysis = await self._analyze_source_content(source_content, source_format)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
        adaptation_strategy = self._determine_adaptation_strategy(source_format, target_formats)
        
        # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏
        adapted_pieces = []
        successful_adaptations = 0
        
        for target_format_str in target_formats:
            try:
                target_format = ContentFormat(target_format_str)
                adapted_piece = await self._adapt_to_format(
                    source_content, content_analysis, target_format, adaptation_strategy
                )
                if adapted_piece:
                    adapted_pieces.append(adapted_piece)
                    successful_adaptations += 1
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç {target_format_str}: {e}")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        processing_time = (datetime.now() - start_time).total_seconds()
        
        # –í—ã—á–∏—Å–ª—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
        success_rate = successful_adaptations / len(target_formats) if target_formats else 0
        
        result = {
            "source_content_id": content_id,
            "source_format": source_format,
            "adapted_pieces": [
                {
                    "content_id": piece.content_id,
                    "format": piece.format.value,
                    "title": piece.title,
                    "content": piece.content,
                    "metadata": piece.metadata,
                    "word_count": piece.word_count,
                    "character_count": piece.character_count,
                    "hashtags": piece.hashtags,
                    "mentions": piece.mentions,
                    "call_to_action": piece.call_to_action
                }
                for piece in adapted_pieces
            ],
            "adaptation_strategy": adaptation_strategy.value,
            "success_rate": success_rate,
            "total_pieces": len(adapted_pieces),
            "processing_time": processing_time,
            "generated_at": datetime.now().isoformat()
        }
        
        return result
    
    async def _analyze_source_content(self, content: str, source_format: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç"""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏
        key_points = self._extract_key_points(content)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        structure = self._analyze_content_structure(content)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–∏—Ç–∞—Ç—ã
        quotes = self._extract_quotes(content)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–æ–Ω
        tone = self._analyze_tone(content)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = self._extract_statistics(content)
        
        return {
            "key_points": key_points,
            "structure": structure,
            "quotes": quotes,
            "tone": tone,
            "statistics": stats,
            "word_count": len(content.split()),
            "character_count": len(content)
        }
    
    def _extract_key_points(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –ø–æ –∞–±–∑–∞—Ü–∞–º
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        key_points = []
        
        for paragraph in paragraphs:
            if len(paragraph) > 50:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∞–±–∑–∞—Ü—ã
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫–∞–∫ –∫–ª—é—á–µ–≤—É—é —Ç–æ—á–∫—É
                sentences = paragraph.split('. ')
                if sentences:
                    key_point = sentences[0].strip()
                    if key_point and not key_point.endswith('.'):
                        key_point += '.'
                    key_points.append(key_point)
        
        return key_points[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10 –∫–ª—é—á–µ–≤—ã–º–∏ —Ç–æ—á–∫–∞–º–∏
    
    def _analyze_content_structure(self, content: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        headings = re.findall(r'^#+\s+(.+)$', content, re.MULTILINE)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∞–±–∑–∞—Ü—ã
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–ø–∏—Å–∫–∏
        lists = re.findall(r'^[\*\-\+]\s+(.+)$', content, re.MULTILINE)
        
        return {
            "headings": headings,
            "paragraphs_count": len(paragraphs),
            "lists_count": len(lists),
            "has_intro": len(paragraphs) > 0,
            "has_conclusion": len(paragraphs) > 2
        }
    
    def _extract_quotes(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–∏—Ç–∞—Ç—ã –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        # –ò—â–µ–º —Ç–µ–∫—Å—Ç –≤ –∫–∞–≤—ã—á–∫–∞—Ö
        quotes = re.findall(r'"([^"]+)"', content)
        
        # –ò—â–µ–º –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        bold_text = re.findall(r'\*\*([^*]+)\*\*', content)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º
        all_quotes = quotes + bold_text
        return all_quotes[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 5 —Ü–∏—Ç–∞—Ç–∞–º–∏
    
    def _analyze_tone(self, content: str) -> str:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        professional_words = ['–∞–Ω–∞–ª–∏–∑', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ', '–¥–∞–Ω–Ω—ã–µ', '—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã', '–º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è']
        casual_words = ['–∫—Ä—É—Ç–æ', '–∫–ª–∞—Å—Å–Ω–æ', '–≤–∞—É', '—Å—É–ø–µ—Ä', '–æ—Ç–ª–∏—á–Ω–æ']
        technical_words = ['–∞–ª–≥–æ—Ä–∏—Ç–º', '—Å–∏—Å—Ç–µ–º–∞', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è', '–ø—Ä–æ—Ü–µ—Å—Å', '—Ñ—É–Ω–∫—Ü–∏—è']
        
        content_lower = content.lower()
        
        professional_count = sum(1 for word in professional_words if word in content_lower)
        casual_count = sum(1 for word in casual_words if word in content_lower)
        technical_count = sum(1 for word in technical_words if word in content_lower)
        
        if professional_count > casual_count and professional_count > technical_count:
            return "professional"
        elif casual_count > professional_count and casual_count > technical_count:
            return "casual"
        elif technical_count > professional_count and technical_count > casual_count:
            return "technical"
        else:
            return "neutral"
    
    def _extract_statistics(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        # –ò—â–µ–º —á–∏—Å–ª–∞ —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏
        percentages = re.findall(r'(\d+(?:\.\d+)?%)', content)
        
        # –ò—â–µ–º —á–∏—Å–ª–∞ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è
        numbers_with_units = re.findall(r'(\d+(?:\.\d+)?\s*(?:—Ç—ã—Å|–º–ª–Ω|–º–ª—Ä–¥|—Ä—É–±|–¥–æ–ª–ª|–µ–≤—Ä–æ|–∫–≥|–≥|–º|–∫–º))', content)
        
        # –ò—â–µ–º –ø—Ä–æ—Å—Ç—ã–µ —á–∏—Å–ª–∞
        numbers = re.findall(r'\b(\d+(?:\.\d+)?)\b', content)
        
        return percentages + numbers_with_units + numbers[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10 —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º–∏
    
    def _determine_adaptation_strategy(self, source_format: str, target_formats: List[str]) -> AdaptationStrategy:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∞–¥–∞–ø—Ç–∞—Ü–∏–∏"""
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        if len(target_formats) > 5:
            return AdaptationStrategy.EXTRACT_KEY_POINTS
        elif any('thread' in fmt for fmt in target_formats):
            return AdaptationStrategy.RESTRUCTURE
        elif any('story' in fmt for fmt in target_formats):
            return AdaptationStrategy.SUMMARIZE
        elif any('infographic' in fmt for fmt in target_formats):
            return AdaptationStrategy.VISUALIZE
        else:
            return AdaptationStrategy.EXTRACT_KEY_POINTS
    
    async def _adapt_to_format(self, source_content: str, content_analysis: Dict[str, Any], target_format: ContentFormat, strategy: AdaptationStrategy) -> Optional[ContentPiece]:
        """–ê–¥–∞–ø—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —à–∞–±–ª–æ–Ω –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞
            template = self.adaptation_templates.get(target_format, {})
            guidelines = self.platform_guidelines.get(target_format)
            
            if not template or not guidelines:
                logger.warning(f"–ù–µ—Ç —à–∞–±–ª–æ–Ω–∞ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ {target_format}")
                return None
            
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
            if strategy == AdaptationStrategy.EXTRACT_KEY_POINTS:
                adapted_content = self._extract_key_points_adaptation(source_content, content_analysis, template)
            elif strategy == AdaptationStrategy.SUMMARIZE:
                adapted_content = self._summarize_adaptation(source_content, content_analysis, template)
            elif strategy == AdaptationStrategy.EXPAND:
                adapted_content = self._expand_adaptation(source_content, content_analysis, template)
            elif strategy == AdaptationStrategy.RESTRUCTURE:
                adapted_content = self._restructure_adaptation(source_content, content_analysis, template)
            elif strategy == AdaptationStrategy.VISUALIZE:
                adapted_content = self._visualize_adaptation(source_content, content_analysis, template)
            else:
                adapted_content = self._conversational_adaptation(source_content, content_analysis, template)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
            if len(adapted_content) > guidelines.max_length:
                adapted_content = adapted_content[:guidelines.max_length-3] + "..."
            elif len(adapted_content) < guidelines.min_length:
                adapted_content = self._expand_content(adapted_content, guidelines.min_length)
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title = self._generate_title(content_analysis, target_format)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ö–µ—à—Ç–µ–≥–∏
            hashtags = self._generate_hashtags(content_analysis, guidelines.hashtag_limit)
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é
            call_to_action = self._generate_call_to_action(target_format)
            
            # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                "strategy": strategy.value,
                "tone": content_analysis.get("tone", "neutral"),
                "word_count": len(adapted_content.split()),
                "character_count": len(adapted_content),
                "has_statistics": len(content_analysis.get("statistics", [])) > 0,
                "has_quotes": len(content_analysis.get("quotes", [])) > 0
            }
            
            return ContentPiece(
                content_id=f"{target_format.value}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                format=target_format,
                title=title,
                content=adapted_content,
                metadata=metadata,
                word_count=len(adapted_content.split()),
                character_count=len(adapted_content),
                hashtags=hashtags,
                mentions=[],
                call_to_action=call_to_action
            )
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –≤ —Ñ–æ—Ä–º–∞—Ç {target_format}: {e}")
            return None
    
    def _extract_key_points_adaptation(self, content: str, analysis: Dict[str, Any], template: Dict[str, Any]) -> str:
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫"""
        key_points = analysis.get("key_points", [])
        if not key_points:
            return content[:500] + "..." if len(content) > 500 else content
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3-5 –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
        selected_points = key_points[:5]
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–æ–Ω–∞
        tone = analysis.get("tone", "neutral")
        if tone == "professional":
            formatted_content = "–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:\n\n" + "\n".join(f"‚Ä¢ {point}" for point in selected_points)
        else:
            formatted_content = "–ì–ª–∞–≤–Ω–æ–µ:\n\n" + "\n".join(f"üî• {point}" for point in selected_points)
        
        return formatted_content
    
    def _summarize_adaptation(self, content: str, analysis: Dict[str, Any], template: Dict[str, Any]) -> str:
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∞–±–∑–∞—Ü—ã
        paragraphs = content.split('\n\n')
        if len(paragraphs) <= 2:
            return content
        
        intro = paragraphs[0]
        conclusion = paragraphs[-1] if len(paragraphs) > 1 else ""
        
        summary = intro
        if conclusion and conclusion != intro:
            summary += f"\n\n{conclusion}"
        
        return summary
    
    def _expand_adaptation(self, content: str, analysis: Dict[str, Any], template: Dict[str, Any]) -> str:
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ"""
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –ø—Ä–∏–º–µ—Ä—ã
        expanded = content
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
        statistics = analysis.get("statistics", [])
        if statistics:
            expanded += f"\n\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {', '.join(statistics[:3])}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ü–∏—Ç–∞—Ç—ã –µ—Å–ª–∏ –µ—Å—Ç—å
        quotes = analysis.get("quotes", [])
        if quotes:
            expanded += f"\n\nüí¨ –¶–∏—Ç–∞—Ç–∞: \"{quotes[0]}\""
        
        return expanded
    
    def _restructure_adaptation(self, content: str, analysis: Dict[str, Any], template: Dict[str, Any]) -> str:
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Ä–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏—é"""
        key_points = analysis.get("key_points", [])
        if not key_points:
            return content
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        restructured = "üßµ Thread:\n\n"
        
        for i, point in enumerate(key_points[:5], 1):
            restructured += f"{i}/5 {point}\n\n"
        
        return restructured
    
    def _visualize_adaptation(self, content: str, analysis: Dict[str, Any], template: Dict[str, Any]) -> str:
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞"""
        key_points = analysis.get("key_points", [])
        statistics = analysis.get("statistics", [])
        
        visual_content = "üìä –ò–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫–∞:\n\n"
        
        if statistics:
            visual_content += f"üìà {statistics[0]}\n"
        
        if key_points:
            visual_content += f"üí° {key_points[0]}\n"
        
        if len(key_points) > 1:
            visual_content += f"üîç {key_points[1]}\n"
        
        return visual_content
    
    def _conversational_adaptation(self, content: str, analysis: Dict[str, Any], template: Dict[str, Any]) -> str:
        """–ê–¥–∞–ø—Ç–∞—Ü–∏—è –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π —Å—Ç–∏–ª—å"""
        key_points = analysis.get("key_points", [])
        if not key_points:
            return content
        
        conversational = "–ü—Ä–∏–≤–µ—Ç! üëã\n\n"
        conversational += f"–•–æ—á—É –ø–æ–¥–µ–ª–∏—Ç—å—Å—è —Å —Ç–æ–±–æ–π: {key_points[0]}\n\n"
        
        if len(key_points) > 1:
            conversational += f"–ê –µ—â–µ: {key_points[1]}\n\n"
        
        conversational += "–ß—Ç–æ –¥—É–º–∞–µ—à—å? üí≠"
        
        return conversational
    
    def _generate_title(self, analysis: Dict[str, Any], target_format: ContentFormat) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞"""
        key_points = analysis.get("key_points", [])
        
        if key_points:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫–∞–∫ –æ—Å–Ω–æ–≤—É –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
            first_point = key_points[0]
            # –£–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ
            title = first_point.rstrip('.,!?')
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            if len(title) > 60:
                title = title[:57] + "..."
            return title
        
        return f"–ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è {target_format.value}"
    
    def _generate_hashtags(self, analysis: Dict[str, Any], limit: int) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö–µ—à—Ç–µ–≥–∏"""
        # –ü—Ä–æ—Å—Ç—ã–µ —Ö–µ—à—Ç–µ–≥–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞
        hashtags = []
        
        tone = analysis.get("tone", "neutral")
        if tone == "professional":
            hashtags.extend(["#–±–∏–∑–Ω–µ—Å", "#–∞–Ω–∞–ª–∏–∑", "#–∏–Ω—Å–∞–π—Ç—ã"])
        elif tone == "technical":
            hashtags.extend(["#—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "#—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞", "#–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏"])
        elif tone == "casual":
            hashtags.extend(["#–ª–∞–π—Ñ—Ö–∞–∫", "#—Å–æ–≤–µ—Ç—ã", "#–º–æ—Ç–∏–≤–∞—Ü–∏—è"])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–µ —Ö–µ—à—Ç–µ–≥–∏
        hashtags.extend(["#–∫–æ–Ω—Ç–µ–Ω—Ç", "#–ø–æ–ª–µ–∑–Ω–æ–µ"])
        
        return hashtags[:limit]
    
    def _generate_call_to_action(self, target_format: ContentFormat) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é"""
        cta_templates = {
            ContentFormat.TELEGRAM_POST: "–ß—Ç–æ –¥—É–º–∞–µ—à—å? –ü–∏—à–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö! üí¨",
            ContentFormat.TWITTER_THREAD: "–°–æ–≥–ª–∞—Å–µ–Ω? –†–µ—Ç–≤–∏—Ç–Ω–∏ –µ—Å–ª–∏ –ø–æ–ª–µ–∑–Ω–æ! üîÑ",
            ContentFormat.INSTAGRAM_CAROUSEL: "–°–æ—Ö—Ä–∞–Ω–∏ –ø–æ—Å—Ç, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å! üíæ",
            ContentFormat.INSTAGRAM_STORY: "–°–≤–∞–π–ø –≤–≤–µ—Ä—Ö –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π! ‚¨ÜÔ∏è",
            ContentFormat.LINKEDIN_ARTICLE: "–ü–æ–¥–µ–ª–∏—Å—å —Å–≤–æ–∏–º –º–Ω–µ–Ω–∏–µ–º –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö! üíº",
            ContentFormat.YOUTUBE_SHORTS: "–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è –Ω–∞ –∫–∞–Ω–∞–ª! üîî",
            ContentFormat.TIKTOK_VIDEO: "–°—Ç–∞–≤—å –ª–∞–π–∫ –∏ –ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è! ‚ù§Ô∏è",
            ContentFormat.PODCAST_SCRIPT: "–°–ª—É—à–∞–π –ø–æ–ª–Ω—ã–π –≤—ã–ø—É—Å–∫ –≤ –ø–æ–¥–∫–∞—Å—Ç–µ! üéß",
            ContentFormat.BLOG_POST: "–ß–∏—Ç–∞–π –±–æ–ª—å—à–µ –Ω–∞ –Ω–∞—à–µ–º —Å–∞–π—Ç–µ! üåê",
            ContentFormat.NEWSLETTER: "–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è –Ω–∞ —Ä–∞—Å—Å—ã–ª–∫—É! üìß",
            ContentFormat.PRESENTATION: "–°–∫–∞—á–∏–≤–∞–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é! üì•",
            ContentFormat.INFOGRAPHIC: "–°–æ—Ö—Ä–∞–Ω–∏ –∏–Ω—Ñ–æ–≥—Ä–∞—Ñ–∏–∫—É! üìä"
        }
        
        return cta_templates.get(target_format, "–ü–æ–¥–µ–ª–∏—Å—å —Å –¥—Ä—É–∑—å—è–º–∏! üë•")
    
    def _expand_content(self, content: str, min_length: int) -> str:
        """–†–∞—Å—à–∏—Ä—è–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã"""
        if len(content) >= min_length:
            return content
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        expanded = content
        
        if len(expanded) < min_length:
            expanded += "\n\nüí° –ü–æ–ª–µ–∑–Ω—ã–π —Å–æ–≤–µ—Ç: —Å–æ—Ö—Ä–∞–Ω–∏ —ç—Ç–æ—Ç –ø–æ—Å—Ç, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å!"
        
        if len(expanded) < min_length:
            expanded += "\n\nü§î –ß—Ç–æ –¥—É–º–∞–µ—à—å –æ–± —ç—Ç–æ–º? –ü–∏—à–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö!"
        
        return expanded
    
    def _update_adaptation_stats(self, result: Dict[str, Any]):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–¥–∞–ø—Ç–∞—Ü–∏–∏"""
        self.adaptation_stats['total_adaptations'] += 1
        
        if result['success_rate'] > 0.8:
            self.adaptation_stats['successful_adaptations'] += 1
        else:
            self.adaptation_stats['failed_adaptations'] += 1
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º
        for piece in result['adapted_pieces']:
            format_name = piece['format']
            if format_name not in self.adaptation_stats['formats_created']:
                self.adaptation_stats['formats_created'][format_name] = 0
            self.adaptation_stats['formats_created'][format_name] += 1
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        current_avg = self.adaptation_stats['average_processing_time']
        total_adaptations = self.adaptation_stats['total_adaptations']
        new_time = result['processing_time']
        
        self.adaptation_stats['average_processing_time'] = (
            (current_avg * (total_adaptations - 1) + new_time) / total_adaptations
        )
    
    def get_adaptation_statistics(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–¥–∞–ø—Ç–∞—Ü–∏–∏"""
        return {
            "total_adaptations": self.adaptation_stats['total_adaptations'],
            "successful_adaptations": self.adaptation_stats['successful_adaptations'],
            "failed_adaptations": self.adaptation_stats['failed_adaptations'],
            "success_rate": (
                self.adaptation_stats['successful_adaptations'] / 
                self.adaptation_stats['total_adaptations'] * 100
                if self.adaptation_stats['total_adaptations'] > 0 else 0
            ),
            "formats_created": self.adaptation_stats['formats_created'],
            "average_processing_time": self.adaptation_stats['average_processing_time'],
            "cache_size": len(self.repurpose_cache),
            "last_activity": self.last_activity.isoformat()
        }
